{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img\n",
    "src=\"https://www.imt-atlantique.fr/sites/default/files/Images/Ecole/charte-graphique/IMT_Atlantique_logo_RVB_Baseline_400x272.jpg\"\n",
    "WIDTH=200 HEIGHT=200>\n",
    "\n",
    "<CENTER>\n",
    "</br>\n",
    "<p><font size=\"5\"> TAF OPE - 2022-2023</span></p>\n",
    "<p><font size=\"4\">  UE Machine Learning and advanced processing methods for multi-sensor data  </font></p>\n",
    "<p></p>\n",
    "<p><font size=\"5\">  Notebook 04: Python lab - Neural Network </font></p>\n",
    "</p></br>\n",
    "</p>\n",
    "</CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this TP, we will build an Artificial Neural Networks (ANN) with one input layer, one hidden layer, and one output layer. We will apply this neural network to find non-linear boundaries \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2560px-Neural_network.png\" width=\"500\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two input $x_1$ and $x_2$. There is a signle hidden layer with $p$ units (nodes): $h_1, h_2, \\ldots, h_p$. Finnaly, there is one output $t$. The arrows that connect them are the weights. There are two weights matrices: $W \\in R^{2\\times p}$ and $U \\in R^{p\\times 1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as la\n",
    "from sklearn.datasets.samples_generator import   make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Define  sigmoid  activiation function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myPrediction(W, U,x):\n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Build our own neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myNeuralNetwork(X, Y, hidden_dim, alpha, W, U):\n",
    "\n",
    "    for n in range(X.shape[0]):\n",
    "        x = np.array(X[n,:], ndmin=2).T\n",
    "        y = Y[n]            \n",
    "   \n",
    "       \n",
    "         \n",
    "\n",
    "        # update the weight for the link between the hidden and the output layers\n",
    "        U +=  \n",
    "\n",
    "        # update the weight for the link between the input and the hidden layers \n",
    "        W +=  \n",
    "    \n",
    "    return W, U\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Create non-linear data by using make_moons function from sklearn dataset. Then use train_test_split function to divide the created dataset into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 300\n",
    "\n",
    "X, y =  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5: Visualize the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6: Train our network with hidden dimensionality = 10 with epochs = 5. Then test the performance of our prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = \n",
    "alpha= 0.01 # learning rate for gradient descent\n",
    "input_dim = 2\n",
    "\n",
    "# weight matrix for Hidden layer \n",
    "W = np.random.randn(hidden_dim, input_dim)  \n",
    "# weight matrix for output layer\n",
    "U = np.random.randn(1, hidden_dim) \n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs =  \n",
    "\n",
    "for e in range(epochs):\n",
    "    W, U = myNeuralNetwork(X_train, y_train, hidden_dim, alpha, W, U)\n",
    "    \n",
    "\n",
    "# using prediction function to predict the labels of test set    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7: Train our network with hidden dimensionality = 100. Then test the performance of our prediction. Give your remarks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
